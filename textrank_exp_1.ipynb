{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd78c051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from datasets import load_dataset\n",
    "from rouge import Rouge\n",
    "import spacy \n",
    "import heapq\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08a467e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3dfc4c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # usuwanie znaków specjalnych i typowych dla datasetu fragmentów\n",
    "    text = text.replace(\"(CNN)\", \"\").replace(\"--\", \"\").replace(\"''\", '\"')\n",
    "    # tokenizacja tekstu na zdania\n",
    "    sentences = sent_tokenize(text)\n",
    "    \n",
    "    # to wywalone bo jest w spacy (token.is_stop)\n",
    "    #stop_words = set(stopwords.words(\"english\"))\n",
    "    preprocessed = []\n",
    "    \n",
    "    for sent in sentences:\n",
    "        doc = nlp(sent.lower())\n",
    "        cleaned_words = []\n",
    "        \n",
    "        for token in doc:\n",
    "            # Uwzgledniamy tylko rzeczowniki, czasowniki, przymiotniki, przysłówki \n",
    "            # (moze trzeba inaczej bo kiepskie wyniki)\n",
    "            if (token.is_alpha and \n",
    "                not token.is_stop and \n",
    "                token.pos_ in {\"NOUN\", \"VERB\", \"ADJ\", \"ADV\"}):\n",
    "                cleaned_words.append(token.lemma_)\n",
    "        \n",
    "        preprocessed.append(\" \".join(cleaned_words))\n",
    "    \n",
    "    return preprocessed, sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98e6dd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def textrank_algorithm(article, \n",
    "                    num_sentences=5, \n",
    "                    damping_factor=0.85, \n",
    "                    similarity_threshold=0.1, \n",
    "                    max_iter=1000, \n",
    "                    tol=1e-6): # dalem tu jakies domyslne, mozna wywalic \n",
    "    preprocessed, original_sentences = preprocess_text(article)\n",
    "    \n",
    "    # TF-IDF, potem do eksperymentu damy tez embeddingi, np. BERT\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(preprocessed)\n",
    "    # obliczamy podobieństwo każdego zdania do każdego zdania i usuwamy self-similarity\n",
    "    sim_matrix = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "    np.fill_diagonal(sim_matrix, 0)\n",
    "\n",
    "    # usuwamy podobieństwa ponizej thresholda (nie sa wazne dla sensu)\n",
    "    sim_matrix[sim_matrix < similarity_threshold] = 0  \n",
    "    \n",
    "    # budujemy graf i smazymy pagerank\n",
    "    graph = nx.from_numpy_array(sim_matrix)\n",
    "    scores = nx.pagerank(graph, \n",
    "                        alpha=damping_factor, \n",
    "                        max_iter=max_iter, \n",
    "                        tol=tol)\n",
    "    \n",
    "    \n",
    "    # Sortowanie według wartości pagerank\n",
    "    ranked_sentences = sorted(((scores[i], i) for i in range(len(original_sentences))), reverse=True)\n",
    "    ranked_indices = [ranked_sentences[i][1] for i in range(min(num_sentences, len(ranked_sentences)))]\n",
    "    # jakby za wolno liczylo odkomentowac dolne i zakomentowac gorne\n",
    "    # ranked_indices = heapq.nlargest(num_sentences, \n",
    "    #                                range(len(scores)), \n",
    "    #                                key=lambda i: scores[i])\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    ranked_indices.sort()\n",
    "    \n",
    "    return \" \".join([original_sentences[i] for i in ranked_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ecf007b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_summaries(dataset, \n",
    "                    num_articles=10, \n",
    "                    num_sentences=5, \n",
    "                    damping_factor=0.85, \n",
    "                    similarity_threshold=0.1, \n",
    "                    max_iter=1000, \n",
    "                    tol=1e-6):\n",
    "    rouge = Rouge()\n",
    "    results = []\n",
    "    \n",
    "    for i in range(num_articles):\n",
    "        article = dataset[\"train\"][i][\"article\"]\n",
    "        reference = dataset[\"train\"][i][\"highlights\"]\n",
    "        \n",
    "        summary = textrank_algorithm(article,\n",
    "                    num_sentences=num_sentences, \n",
    "                    damping_factor=damping_factor, \n",
    "                    similarity_threshold=similarity_threshold, \n",
    "                    max_iter=max_iter, \n",
    "                    tol=tol)\n",
    "        \n",
    "        # ewaluacja modelu za pomoca 3 rogue.\n",
    "        scores = rouge.get_scores(summary, reference)[0]\n",
    "        \n",
    "        # Zapis wyników\n",
    "        results.append({\n",
    "            \"article_id\": i+1,\n",
    "            \"summary\": summary,\n",
    "            \"reference\": reference,\n",
    "            \"rouge-1\": scores[\"rouge-1\"][\"f\"],\n",
    "            \"rouge-2\": scores[\"rouge-2\"][\"f\"],\n",
    "            \"rouge-l\": scores[\"rouge-l\"][\"f\"]\n",
    "        })\n",
    "        \n",
    "        print(f\"Artykuł {i+1}:\")\n",
    "        print(\"Podsumowanie:\", summary)\n",
    "        print(\"Docelowy highlight:\", reference)\n",
    "        print(\"ROUGE-L:\", scores[\"rouge-l\"][\"f\"])\n",
    "        print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(\"textrank_evaluation.csv\", index=False)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8f08593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artykuł 1:\n",
      "Podsumowanie: Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties. \"People are always looking to say 'kid star goes off the rails,'\" he told reporters last month. His latest outing as the boy wizard in \"Harry Potter and the Order of the Phoenix\" is breaking records on both sides of the Atlantic and he will reprise the role in the last two films. Watch I-Reporter give her review of Potter's latest » . Meanwhile, he is braced for even closer media scrutiny now that he's legally an adult: \"I just think I'm going to be more sort of fair game,\" he told Reuters.\n",
      "Docelowy highlight: Harry Potter star Daniel Radcliffe gets £20M fortune as he turns 18 Monday .\n",
      "Young actor says he has no plans to fritter his cash away .\n",
      "Radcliffe's earnings from first five Potter films have been held in trust fund .\n",
      "ROUGE-L: 0.2556390937961446\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Artykuł 2:\n",
      "Podsumowanie: Here, Soledad O'Brien takes users inside a jail where many of the inmates are mentally ill. An inmate housed on the \"forgotten floor,\" where many mentally ill inmates are housed in Miami before trial. He is well known in Miami as an advocate for justice and the mentally ill. Leifman says about one-third of all people in Miami-Dade county jails are mentally ill. Leifman tells me that these prisoner-patients will often circulate through the system, occasionally stabilizing in a mental hospital, only to return to jail to face their charges. Over the years, he says, there was some public outcry, and the mentally ill were moved out of jails and into hospitals.\n",
      "Docelowy highlight: Mentally ill inmates in Miami are housed on the \"forgotten floor\"\n",
      "Judge Steven Leifman says most are there as a result of \"avoidable felonies\"\n",
      "While CNN tours facility, patient shouts: \"I am the son of the president\"\n",
      "Leifman says the system is unjust and he's fighting for change .\n",
      "ROUGE-L: 0.24999999550138896\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Artykuł 3:\n",
      "Podsumowanie: \"The whole bridge from one side of the Mississippi to the other just completely gave way, fell all the way down,\" survivor Gary Babineau told CNN. The whole bridge is down.\" \"I could see the whole bridge as it was going down, as it was falling,\" Babineau said. I saw a couple cars fall,\" he said. \"So I stayed in my car until the cars quit falling for a second, then I got out real quick, ran in front of my truck  because behind my truck was just a hole  and I helped a woman off of the bridge with me.\n",
      "Docelowy highlight: NEW: \"I thought I was going to die,\" driver says .\n",
      "Man says pickup truck was folded in half; he just has cut on face .\n",
      "Driver: \"I probably had a 30-, 35-foot free fall\"\n",
      "Minnesota bridge collapsed during rush hour Wednesday .\n",
      "ROUGE-L: 0.1834862340476392\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Artykuł 4:\n",
      "Podsumowanie: WASHINGTON   Doctors removed five small polyps from President Bush's colon on Saturday, and \"none appeared worrisome,\" a White House spokesman said. A colonoscopy is the most sensitive test for colon cancer, rectal cancer and polyps, small clumps of cells that can become cancerous, according to the Mayo Clinic. Small polyps may be removed during the procedure. Snow said on Friday that Bush had polyps removed during colonoscopies before becoming president. Watch Snow talk about Bush's procedure and his own colon cancer » .\n",
      "Docelowy highlight: Five small polyps found during procedure; \"none worrisome,\" spokesman says .\n",
      "President reclaims powers transferred to vice president .\n",
      "Bush undergoes routine colonoscopy at Camp David .\n",
      "ROUGE-L: 0.2528735592231471\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Artykuł 5:\n",
      "Podsumowanie: In papers filed Friday with a federal court in Virginia, Vick also admitted that he and two co-conspirators killed dogs that did not fight well. \"The defendant will plead guilty because the defendant is in fact guilty of the charged offense,\" the plea agreement said. In an additional summary of facts, signed by Vick and filed with the agreement, Vick admitted buying pit bulls and the property used for training and fighting the dogs, but the statement said he did not bet on the fights or receive any of the money won. Around April, Vick, Peace and Phillips tested some dogs in fighting sessions at Vick's property in Virginia, the statement said. The judge in the case will have the final say over the plea agreement.\n",
      "Docelowy highlight: NEW: NFL chief, Atlanta Falcons owner critical of Michael Vick's conduct .\n",
      "NFL suspends Falcons quarterback indefinitely without pay .\n",
      "Vick admits funding dogfighting operation but says he did not gamble .\n",
      "Vick due in federal court Monday; future in NFL remains uncertain .\n",
      "ROUGE-L: 0.17094016674702325\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Artykuł 6:\n",
      "Podsumowanie: \"We just want to thank everyone who has come forward,\" he said. Shortly after Youssif's story aired Wednesday, the Children's Burn Foundation  a nonprofit organization based in Sherman Oaks, California, that provides support for burn victims locally, nationally and internationally  agreed to pay for the transportation for Youssif and his family to come to the United States and to set up a fund for donations. \"We are prepared to have them come here, set them up in a housing situation, provide support for them and begin treatment,\" said Barbara Friedman, executive director of the Children's Burn Foundation. But none of that matters  getting help for their boy is first and foremost. But he didn't want to; his mother says he's shy outside of their home.\n",
      "Docelowy highlight: Parents beam with pride, can't stop from smiling from outpouring of support .\n",
      "Mom: \"I was so happy I didn't know what to do\"\n",
      "Burn center in U.S. has offered to provide treatment for reconstructive surgeries .\n",
      "Dad says, \"Anything for Youssif\"\n",
      "ROUGE-L: 0.13008129654306314\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Artykuł 7:\n",
      "Podsumowanie: She says her husband thinks she is cleaning houses when she leaves home. Suha's husband thinks that she is cleaning houses when she goes away. \"It's increasing,\" Suha says. \"They took this path but they are not pleased,\" Rahim says. \"Everything is for the children.\n",
      "Docelowy highlight: Aid workers: Violence, increased cost of living drive women to prostitution .\n",
      "Group is working to raise awareness of the problem with Iraq's political leaders .\n",
      "Two Iraqi mothers tell CNN they turned to prostitution to help feed their children .\n",
      "\"Everything is for the children,\" one woman says .\n",
      "ROUGE-L: 0.1944444394791668\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Artykuł 8:\n",
      "Podsumowanie: BOGOTA, Colombia   A key rebel commander and fugitive from a U.S. drug trafficking indictment was killed over the weekend in an air attack on a guerrilla encampment, the Colombian military said Monday. Alleged cocaine trafficker and FARC rebel Tomas Medina Caracas in an Interpol photo. Tomas Medina Caracas, known popularly as \"El Negro Acacio,\" was a member of the high command of the Fuerzas Armadas Revolucionarias de Colombia and, according to Colombian and U.S. officials, helped manage the group's extensive cocaine trafficking network. U.S. officials alleged Medina Caracas managed the rebel group's sales of cocaine to international drug traffickers, who in turn smuggled it into the United States. Established in 1964 as the military wing of the Colombian Communist Party, FARC is Colombia's oldest, largest, most capable and best-equipped Marxist rebel group, according to the U.S. Department of State.\n",
      "Docelowy highlight: Tomas Medina Caracas was a fugitive from a U.S. drug trafficking indictment .\n",
      "\"El Negro Acacio\" allegedly helped manage extensive cocaine network .\n",
      "U.S. Justice Department indicted him in 2002 .\n",
      "Colombian military: He was killed in an attack on a guerrilla encampment .\n",
      "ROUGE-L: 0.40310077117000187\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Artykuł 9:\n",
      "Podsumowanie: WASHINGTON   White House press secretary Tony Snow, who is undergoing treatment for cancer, will step down from his post September 14 and be replaced by deputy press secretary Dana Perino, the White House announced Friday. He took a big pay cut, he said, when he left his previous jobs as anchor and political analyst for Fox News. His colon was removed, and after six months of treatment, doctors said the cancer was in remission. Perino announced March 27 that Snow's cancer had recurred, and that doctors had removed a growth from his abdomen the day before. The press secretary, whose hair has turned gray during chemotherapy treatment, said his black hair is expected to grow back in about a month.\n",
      "Docelowy highlight: President Bush says Tony Snow \"will battle cancer and win\"  Job of press secretary \"has been a dream for me,\" Snow says  Snow leaving on September 14, will be succeeded by Dana Perino .\n",
      "ROUGE-L: 0.18181817808892842\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Artykuł 10:\n",
      "Podsumowanie:   Police and FBI agents are investigating the discovery of an empty rocket launcher tube on the front lawn of a Jersey City, New Jersey, home, FBI spokesman Sean Quinn said. Niranjan Desai discovered the 20-year-old AT4 anti-tank rocket launcher tube, a one-time-use device, lying on her lawn Friday morning, police said. The launcher \"is no longer operable and not considered to be a hazard to public safety,\" police said, adding there was no indication the launcher had been fired recently. Army officials said they could not determine if the launcher had been fired, but indicated they should know once they find out where it came from. An Army official said the device is basically a shoulder-fired, direct-fire weapon used against ground targets  a modern-day bazooka  and it is not wire-guided.\n",
      "Docelowy highlight: Empty anti-tank weapon turns up in front of New Jersey home .\n",
      "Device handed over to Army ordnance disposal unit .\n",
      "Weapon not capable of being reloaded, experts say .\n",
      "ROUGE-L: 0.13223140158459132\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Średnie wyniki ROUGE:\n",
      "rouge-1    0.235092\n",
      "rouge-2    0.065376\n",
      "rouge-l    0.215462\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# tu na wejsciu ile artykulów streszczamy i jakie hiperparametry, na razie dalem domyslne\n",
    "results_df = evaluate_summaries(dataset, num_articles=10)\n",
    "print(\"Średnie wyniki ROUGE:\")\n",
    "print(results_df[[\"rouge-1\", \"rouge-2\", \"rouge-l\"]].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4d54811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rozkład długości:\n",
      "- Krótkie: 37122 artykułów\n",
      "- Średnie: 173617 artykułów\n",
      "- Długie: 62698 artykułów\n"
     ]
    }
   ],
   "source": [
    "# kod do 2 pytania eksperymentalnego\n",
    "def create_length_subsets(dataset, splits=[2000, 5000, 8000]):\n",
    "    # tworzymy podzbiory po ilosci znakow w artykule\n",
    "    subsets = {\n",
    "        \"short\": {\"articles\": [], \"highlights\": []},\n",
    "        \"medium\": {\"articles\": [], \"highlights\": []},\n",
    "        \"long\": {\"articles\": [], \"highlights\": []}\n",
    "    }\n",
    "    \n",
    "    for example in dataset[\"train\"]:\n",
    "        char_count = len(example[\"article\"])\n",
    "        \n",
    "        if char_count <= splits[0]:\n",
    "            key = \"short\"\n",
    "        elif splits[0] < char_count <= splits[1]:\n",
    "            key = \"medium\"\n",
    "        elif splits[1] < char_count <= splits[2]:\n",
    "            key = \"long\"\n",
    "        else:\n",
    "            continue  # Pomijamy artykuły > 8000 znaków\n",
    "            \n",
    "        subsets[key][\"articles\"].append(example[\"article\"])\n",
    "        subsets[key][\"highlights\"].append(example[\"highlights\"])\n",
    "    \n",
    "    print(\"Rozkład długości:\")\n",
    "    print(f\"- Krótkie: {len(subsets['short']['articles'])} artykułów\")\n",
    "    print(f\"- Średnie: {len(subsets['medium']['articles'])} artykułów\")\n",
    "    print(f\"- Długie: {len(subsets['long']['articles'])} artykułów\")\n",
    "    \n",
    "    return subsets\n",
    "\n",
    "subsets = create_length_subsets(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc3a5f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_subsets(subsets, num_samples=100):\n",
    "    results = {}\n",
    "    rouge = Rouge()\n",
    "    params = { #parametry do poszczegolnych dlugosci zdan\n",
    "        \"short\": {\n",
    "            \"num_sentences\": 3,\n",
    "            \"damping_factor\": 0.85,\n",
    "            \"similarity_threshold\": 0.1,\n",
    "            \"max_iter\": 1000,\n",
    "            \"tol\": 1e-6\n",
    "        },\n",
    "        \"medium\": {\n",
    "            \"num_sentences\": 5,\n",
    "            \"damping_factor\": 0.85,\n",
    "            \"similarity_threshold\": 0.15,\n",
    "            \"max_iter\": 1000,\n",
    "            \"tol\": 1e-6\n",
    "        },\n",
    "        \"long\": {\n",
    "            \"num_sentences\": 7,\n",
    "            \"damping_factor\": 0.8,\n",
    "            \"similarity_threshold\": 0.2,\n",
    "            \"max_iter\": 2000,\n",
    "            \"tol\": 1e-8\n",
    "        }}\n",
    "    \n",
    "    for length_key in [\"short\", \"medium\", \"long\"]:\n",
    "        scores = []\n",
    "        for art, ref in zip(subsets[length_key][\"articles\"][:num_samples], \n",
    "                          subsets[length_key][\"highlights\"][:num_samples]):\n",
    "            try:\n",
    "                summary = textrank_algorithm(\n",
    "                    art,\n",
    "                    num_sentences=params[length_key][\"num_sentences\"],\n",
    "                    damping_factor=params[length_key][\"damping_factor\"],\n",
    "                    similarity_threshold=params[length_key][\"similarity_threshold\"],\n",
    "                    max_iter=params[length_key][\"max_iter\"],\n",
    "                    tol=params[length_key][\"tol\"]\n",
    "                )\n",
    "                if summary.strip():\n",
    "                    scores.append(rouge.get_scores(summary, ref)[0][\"rouge-l\"][\"f\"])\n",
    "            except Exception as e:\n",
    "                print(f\"Błąd dla {length_key}: {str(e)}\")\n",
    "                continue\n",
    "                \n",
    "        results[length_key] = np.mean(scores) if scores else 0\n",
    "    \n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfd86cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Użycie:\n",
    "results_exp2 = evaluate_on_subsets(subsets)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(results_exp2.keys(), results_exp2.values())\n",
    "plt.title(\"ROUGE-L dla różnych długości tekstów\")\n",
    "plt.ylabel(\"Średni F1-Score\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c917af",
   "metadata": {},
   "source": [
    "EWENTUALNE TODO:\n",
    "\n",
    "Twoje wyniki wskazują, że model nie wybiera optymalnych zdań, ale nie są beznadziejne. Aby je poprawić:\n",
    "\n",
    "Mniej agresywny preprocessing,\n",
    "\n",
    "Optymalizacja hiperparametrów,\n",
    "\n",
    "Eksperymenty z lepszymi reprezentacjami zdań."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
